How to Use npm as a Build Tool 
 
 
 
 
 Update: I frequently get asked, considering this post is now years old, whether or not I still stand by the advice in this post, and whether new developers should use npm as a build tool. The advice still stands, and I believe developers should use npm as a build tool. Myself; I’ve been Gulp & Grunt free since 2013™. Should I ever change my stance on this, I will immediately update this post.
 
 Last month I noted my opinions on why we should stop using Grunt, Gulp et al . I suggested we should start using npm instead. npm’s directive can do everything that these build tools can, more succinctly, more elegantly, with less package dependencies and less maintainence overhead. The first draft of the original post was way over 6,000 words - because it went in depth into how npm could be used as an alternative, but I removed it for brevity - and because the point of that post was me expressing opinions, not a tutorial post. However, the response was pretty overwhelming - many people replied telling me that these build tools offers them features that npm cannot (or does not), some developers were brazen enough to present me with a Gruntfile and say “how could this be done in npm?!”. I thought I’d pull out how-tos from the original draft and make a new post, just focussing on how to do these common tasks with npm. 
 npm is a fantastic tool that offers much more than meets the eye. It has become the backbone of the Node.js community - many, including me, use it pretty much every day. In fact, looking at my Bash History (well, Fish history) is second only to as my most used command. Still, I find new features in npm every day (and of course, new ones are still being developed!). Most of these aim at making npm a great package manager, but npm has a great subset of functionality decidated to running tasks to facilitate in a packages lifecycle - in other words, it is a great tool for build scripts. 
 npm Scripts 
 Firstly, we need to figure out how npm can manage our build scripts. As part of npm’s core, it has the command ( for short). This command dives into your and pulls out the Object. The first argument passed to refers to a property in the object - it will execute the property’s value as a command in the operating systems default shell (usually Bash, except on Windows - but we’ll get to that later). So let’s say you have a config that looks like this: 
 
 If you run - npm will spawn a shell and run . If you run , npm will spawn a shell and run . The shell environment has your folder added to the which means any of the dependencies you have that install binaries will be runnable directly - in other words, no need to put or . If you run without any arguments it gives you a list of the available commands to run, like so: 
 
 The shell environment provides lots of helpful features to make sure your scripts are as succinct as they can be. For example the shell’s has your folder inside of it, meaning any dependencies you install which have binaries can be called directly from a scripts shell. Also, there’s a whole slew of super convenient environment variables that npm exposes, such as the currently running task, the package name and version, npm loglevel, and so on. Find them all out by making a script that runs , and running it, like so: 
 
 Shortcut scripts 
 npm also provides a few convinient shortcuts. The , , commands are all shortcuts for their equivalents, e.g. is just a shortcut for . These shortcuts are useful for 2 reasons: 
 
 These are common tasks that most projects will use, and so it’s nice to not have to type as much each time. 
 Much more importanlty - it provides a standard interface within npm for testing, starting and stopping a package. Many CI tools, such as Travis, take advantage of this behaviour by making the default command for a Node.js project . It also makes introducing new developers to your project a breeze, if they know they can simply run scripts like without ever having to read any docs. 
 
 Pre and Post Hooks 
 Another cool feature about npm is that any script that can be executed also has a set of and hooks, which are simply definable in the object. For example, if you execute , despite npm having no preconceived idea of what the task is, it will immediately run , followed by , followed by . The same is true for any command, including (, , ). The pre and post scripts are also exit-code-sensitive, meaning if your script exits with a non-zero exit code, then NPM will immediately stop, and not run the and scripts. You can’t a script though, so gets ignored. npm also runs the and hooks for a few internal commands: , , , . You can’t override the behaviours for the internal commands - but you can affect their behaviour with and scripts. This means you can do cool stuff like: 
 
 Passing Arguments 
 Another cool feature with npm (since npm 2.0.0, at least ) is passing argument sets through to the underlying tools. This can be a little complex, but here’s an example: 
 
 With this config, we can simply run - which runs , but we can extend it with custom parameters with a prefix. For example will run , or more usefully will expand to (which runs only the tests with “parser” in the title). In the package.json we have which effectively runs . This setup can be incredibly useful for composing commands together for some advanced configurations. 
 NPM Config Variables 
 One last thing that is worth mentioning - npm has a directive for your . This lets you set arbitrary values which can be picked up as environment variables in your . Here’s an example: 
 
 Here, the object has property - set to . All config options are exposed as environment variables prefixed with (which, admittedly, does make the variable names a mouthful). In the above example, the command uses the variable which gets expanded to . This can get replaced in two convinient ways: 
 
 Just like the task, you can change the reporter config variable to - by using . You’d replace with your project’s name, and with the config variable to override. 
 They can also be overriden as part of a user’s config. By running - an entry in my appears () which is read at runtime, and overrides the variable, meaning that on my local machine, forever more, gets expanded to . I can remove my personalised setting for this using . A good set up for this is to have some sensible defaults in your - but your own customisations can be tucked away inside your own . 
 
 Now, if I’m totally honest I’m not in love with the way this works. While the setup seems trivial (having a object in your JSON), trying to use them is seems too verbose and complicated. I would also like a simpler way to override package configs, without specifying the package’s name - it’d be awesome if standard conventions could come into place where I could set my favourite mocha reporter for all packages in my . 
 The other downside to these configs is that they’re not very Windows friendly - Windows uses for variable substitution, while bash uses . They work fine if you use them within a Node.js script, but if anyone knows of a way to get them working in Windows via the shell commands, let me know! 
 The Windows Problem 
 Let’s get something out of the way before we progress. Because npm is reliant on the operating systems shell to run scripts commands, they can quickly become unportable. While Linux, Solaris, BSD and Mac OSX come preinstalled with Bash as the default shell, Windows does not. On Windows, npm will resort to using Windows command prompt for these things. 
 Frankly, this is less of a problem than it seems. A good chunk of syntax that works in Bash will also work in Windows command prompt the same way: 
 
 for chaining tasks 
 for running tasks simaltaneously 
 for inputting the contents () of a file to a command 
 for redirecting output () of a command and dumping it to a file 
 for redirecting output () of a command and sending it to another command 
 
 The biggest problems between the two is the availability and naming of commands (e.g. is in Windows) and variables (Windows uses for variables, Bash ). I feel like both of these are completely surmountable problems: 
 
 Rather than relying on built in commands, you could simply use alternatives - for example instead of using , use the npm rimraf package. 
 Rather than trying to use syntax that is not cross compatible, stick to just the above ones. You’d be surprised just how much you can get done with just , , , and . Variables are for suckers anyway. 
 
 Ok, lets get to the brass tacks of this post. If we want to replace build tools like Grunt or Gulp, we need like-for-like replacements for plugins and features of these tools. I’ve taken the most popular tasks & paradigms from various projects, and questions from commenters of my last post and demonstrated how to do them in npm: 
 Using multiple files 
 I had a few people responding to my last post, saying the benefit of task runners is their ability to handle multiple files in tasks using file “globs” which look like , or . This feature was actually inspired from Bash, which in turn was inspired from the command from Unix in 1969. The shell will automatically look at a command line arguments such as and expand the stars out as wildcards. Using two stars allows it to search recursively. If you’re on a Mac or Linux machine, try opening up your shell and playing with it (try something like ). 
 Now, the problem herein lies that, of course, the Windows command line does not have this functionality. Luckily, when given a command line argument like - Windows passes it verbatum to the application, meaning that tool vendors can install compatibility libraries to give Windows glob like functionality. Many, many tools on npm do; the two most popular glob libraries, minimatch and glob , share 1500 dependents, including JSHint, JSCS, Mocha, Jade, Stylus, Node-Sass… the list goes on. 
 This means you can just use file globs within npm scripts, like so: 
 
 Running multiple tasks 
 Grunt, Gulp etc all have the capability of tying multiple tasks up together to make one single task - typically useful for building or testing. With npm you have two options here - depending on which one is semantically the right fit. You can either use the or hooks - which are a good fit if the task is a prerequisite thing (i.e concating js before minfiying it), or you can use the bash operator - like so: 
 
 In the above example will execute both and - but not before running the task. Using this pattern you can also run the or tasks separately, and will also run beforehand. Tasks can be composed and chained like this as much as you like, and it is all Windows compatible. 
 Streaming to multiple tasks 
 One of Gulp’s biggest features is that it streams the output seamlessly from one task to the next (as opposed to Grunt which constantly dips in and out of the filesystem). Bash and the Windows command line have the pipe operator (), which can stream one command’s output () and send it to another command’s input (). Let’s say you want to run all of your CSS first through Autoprefixer , then CSSMin , then output to a file (using the operator, which outputs to a given file): 
 
 As you can see adds the CSS vendor prefixes to our CSS, which is then piped to which minifies the output - then the whole thing gets dumped into . Most good tools will support and and the above code is fully compatible with Windows, Mac and Linux. 
 Version Bumping 
 Version bumping is a popular Grunt or Gulp task. Effectively it increments the version number up by one inside the package.json, makes a git commit, and tags said commit. 
 This actually comes baked into npm (it is a package manager after all). Simply run to increment the patch number (e.g. ), to increment the minor version number (e.g. ) or (e.g. ). It’ll commit and tag up your package for you, all that is left is to and . 
 This can be fully customised too. For example, if you don’t want it running , simply run it with the flag (or set it to permanently not with ). Want to configure the commit message? Simply run it with the flag, e.g. (set it permanently with ). You can even get it to sign the tags for you, by running with the flag (or, once again, set it permanently with ). 
 Clean 
 Many build runners come with a task. This task usually just removes a bunch of files so you can start with a fresh working copy to start building into. Well, turns out that Bash has a pretty good clean command all by itself: . Passing the (recursive) flag lets remove directories too! It couldn’t be simpler: 
 
 If you really need to have Windows support, it does not support - luckily there is rimraf which is a cross-compatible tool to do the same thing: 
 
 Compiling files to unique names 
 Effectively, trying to replace the functionality of gulp-hash and grunt-hash - take an input of JS and name it with the hash of its contents. This one turned out to be really complex to do using existing command line tools, so I had a look on npm to see if anything fit the bill, and it didn’t - so I wrote one (I can hear the Grunt/Gulp proponents telling me I cheated already). I have two points about this - firstly, it’s pretty disappointing to see lots of siloed efforts from various plugin authors - and no generic solutions that work with any build tool. Secondly - if you can’t find something that fits, write your own! My hashmark library clocks in around the same lines of code as the grunt/gulp versions, and has a similar or better featureset, depending on the plugin - mine even supports streaming! Going back to the autoprefixer example, we can output a file with a specific hash using pipes: 
 
 Now the ouput of will ouput a file in dist named with a hash, such as . 
 Watch 
 This is definitely the most popular reason why people using Grunt/Gulp, and by far the most requested example from comments around my previous post . A lot of these build tools come with commands for watching a filesystem, detecting changes to files (e.g. from saving), and then reloading the server/recompiling assets/rerunning tests. Very useful for rapid development. It seems like most developers replying to my last post simply assumed that this wasn’t an option outside of Grunt/Gulp (or perhaps thought it was something too difficult to do without them). 
 Well, most tools facilitate this option themselves - and usually are much more in tune with the intricacies of the files that should be listened for. For example Mocha has the option, as does Stylus , Node-Sass , Jade , Karma , and others. You could use these options like so; 
 
 Of course, not all tools support this, and even when they do - you might want to compose multiple compile targets into one task which watches for changes and runs the whole set. There are tools that watch files and execute commands when files change, for example watch , onchange , dirwatch , or even nodemon : 
 
 There you go - pretty painless. This 13 lines of JSON will watch our whole project directory, and build HTML, CSS and JS assets every time any file changes. Just run and start developing! You could even optimise this further, with a little tool I wrote (once again, while writing this post): Parallelshell , which will keep multiple processes running at one time - a little like this: 
 
 Now running will run the individual watchers all through Parallelshell and if, for example, you only change the CSS, then only the CSS will recompile. If you change the JS then only the JS will recompile and so on. Parallelshell combines the outputs ( and ) of each of the tasks, and will listen to the exit code to ensure logs and failed builds propagate out (unlike the Bash/Windows operator). 
 LiveReload 
 LiveReload was another popular one. If you don’t know what LiveReload is - its a combination of command line tool and browser extension (or custom server) - as files change, LiveReload triggers the page you’re looking at to reload meaning you never have to press refresh. The npm package live-reload is a pretty suitable command line client for this - it runs a server which only serves a JS file, which if you include on your page will notify the page of changes. Simple, yet effective. Here’s an example of how to get it working: 
 
 
 Now running - when you visit the HTML page it’ll start listening to the livereload server. Any changes to files in the directory will notifiy clients, and the page will be reloaded. 
 Running tasks that don’t come with binaries 
 It was pointed out to me that there are libs that don’t come with binaries - such as favicon - and so Grunt/Gulp plugins can be useful because they wrap the tools so they can be used within the task runners. If you find a package that you want to use, but it doesn’t have a binary then simply write some JavaScript! You would have to if using Grunt or Gulp, so don’t be afraid to just chuck a bit of JavaScript somewhere that wires it all up (or even better, submit a PR to the maintainers convincing them to support a command line interface!): 
 
 
 A fairly complex config 
 In my previous post many were telling me I was missing the point about task runners - they’re for wiring up complex sets of tasks, not just running odd tasks. So I thought I’d wrap up this piece with a complex set of tasks typical of a multi-hundred-line Gruntfile. For this example I want to do the following: 
 
 Take my JS and lint, test & compile it into 1 versioned file (with a separate sourcemap) and upload it to S3 
 Compile Stylus into CSS, down to a single, versioned file (with separate sourcemap), upload it to S3 
 Add watchers for testing and compilation 
 Add a static file server to see my single page app in a web browser 
 Add livereload for CSS and JS 
 Have a task that combines all these files so I can type one command and spin up an environment 
 For bonus points, open a browser window automagically pointing to my website 
 
 I’ve chucked up a simple repository on GitHub called npm-scripts-example . It contains the layout for a basic website, and a package.json to fit the above tasks. The lines you’re probably interested in are: 
 
 (If you’re wondering what the flag is, it just silences output from npm on those tasks, cleaning up the log output, try disabling them to see the difference) 
 To do the equivalent in Grunt, it’d take a Gruntfile of a few hundred lines, plus (my finger in the air estimate) around 10 extra dependencies. It’s certainly subjective as to which version would be more readable - and while npm is certainly not the holy grail of readability, I personally think the npm scripts directive is easier to reason about (i.e. I can see all tasks and what they do, at a glance). 
 Conclusion 
 Hopefully this article shows you how capable npm can be as a build tool. Hopefully it has demonstrated to you that tools like Gulp and Grunt should not always be the first thing to jump to in a project, and that tools you probably already have on your system are worth investigating. 
 As always, feel free to discuss this with me on The Twitter, I’m @keithamus , you can “Follow” me there too, apparently.